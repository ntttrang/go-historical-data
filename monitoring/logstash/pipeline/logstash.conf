input {
  tcp {
    port => 5044
    codec => json_lines
    type => "app-logs"
  }
  
  udp {
    port => 5044
    codec => json_lines
    type => "app-logs"
  }
}

filter {
  # Parse timestamp
  if [timestamp] {
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
    }
  }

  # Add service metadata
  mutate {
    add_field => {
      "service" => "historical-data-api"
      "environment" => "%{[app_env]}"
    }
  }

  # Parse log level
  if [level] {
    mutate {
      uppercase => [ "level" ]
    }
  }

  # Extract error details
  if [level] == "ERROR" or [level] == "FATAL" or [level] == "PANIC" {
    mutate {
      add_tag => [ "error" ]
    }
  }

  # Extract trace context for correlation
  if [trace_id] {
    mutate {
      add_field => {
        "trace_context" => "%{trace_id}:%{span_id}"
      }
    }
  }

  # Parse CSV upload metrics
  if [csv_rows_processed] {
    mutate {
      add_tag => [ "csv_upload" ]
      convert => {
        "csv_rows_processed" => "integer"
        "csv_rows_failed" => "integer"
        "csv_batch_size" => "integer"
      }
    }
  }

  # Parse HTTP request logs
  if [method] and [path] {
    mutate {
      add_tag => [ "http_request" ]
      add_field => {
        "http_endpoint" => "%{method} %{path}"
      }
    }
  }

  # Parse database query logs
  if [query_duration] {
    mutate {
      add_tag => [ "database" ]
      convert => {
        "query_duration" => "float"
      }
    }
  }

  # Geoip enrichment for client IPs (optional)
  if [client_ip] {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => [ "host", "port" ]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "historical-data-api-%{+YYYY.MM.dd}"
    
    # Template for index mapping
    template_name => "historical-data-api"
    template_overwrite => true
  }

  # Debug output (optional - comment out in production)
  # stdout {
  #   codec => rubydebug
  # }
}
